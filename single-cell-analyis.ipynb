{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bf4944ad-ac03-4200-a224-4a5e9b06911c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T22:43:52.248711Z",
     "iopub.status.busy": "2022-11-08T22:43:52.248392Z",
     "iopub.status.idle": "2022-11-08T22:43:52.254261Z",
     "shell.execute_reply": "2022-11-08T22:43:52.253824Z",
     "shell.execute_reply.started": "2022-11-08T22:43:52.248688Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.optim.swa_utils import AveragedModel\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchmetrics import PearsonCorrCoef\n",
    "from torch.nn import functional \n",
    "from torch.nn.modules import dropout\n",
    "from torch import Tensor\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import tables\n",
    "import pickle\n",
    "import copy\n",
    "import tables\n",
    "import random\n",
    "import zipfile\n",
    "import sklearn\n",
    "import scipy\n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, scale\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from scipy.stats import pearsonr, mode\n",
    "import scipy.sparse as sps\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a0ed3cfd-38e6-4455-87f2-5ec1c0c95493",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T22:43:52.450699Z",
     "iopub.status.busy": "2022-11-08T22:43:52.450427Z",
     "iopub.status.idle": "2022-11-08T22:43:52.454035Z",
     "shell.execute_reply": "2022-11-08T22:43:52.453568Z",
     "shell.execute_reply.started": "2022-11-08T22:43:52.450676Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1c5c7e-6c85-4f49-abcd-d693457ff9a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab8d7ee4-556e-4bbb-ace3-d021ae5d4203",
   "metadata": {},
   "source": [
    "# feature engineering and tricks utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "32d75da7-63a7-49ff-840e-e510febbb85e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T22:43:52.983607Z",
     "iopub.status.busy": "2022-11-08T22:43:52.983328Z",
     "iopub.status.idle": "2022-11-08T22:43:52.988615Z",
     "shell.execute_reply": "2022-11-08T22:43:52.988116Z",
     "shell.execute_reply.started": "2022-11-08T22:43:52.983585Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_most_associated_target_input_pairs(data_x, data_y):\n",
    "    \n",
    "    list_argsort_correlations = []\n",
    "    list_correlations = []\n",
    "    \n",
    "    for j in range(data_y.shape[1]):\n",
    "        if j % 1000 == 0:\n",
    "            print(f\"computing for target number {j+1}\")\n",
    "            \n",
    "        random_indices = np.random.choice(data_x.shape[0], 1000, replace=False)\n",
    "        \n",
    "        target = data_y[random_indices, j]\n",
    "        \n",
    "        corr_list = [np.abs(np.corrcoef(data_x[random_indices, i], target)[0,1])*-1 for i in range(data_x.shape[1])]\n",
    "        argsort_array = np.argsort(corr_list)\n",
    "        \n",
    "        list_argsort_correlations.append(argsort_array)\n",
    "        list_correlations.append(np.array(corr_list)[argsort_array])\n",
    "        \n",
    "    return list_argsort_correlations, list_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "007e2f42-d2dc-48f2-941b-ff112189562e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T22:43:53.259563Z",
     "iopub.status.busy": "2022-11-08T22:43:53.259288Z",
     "iopub.status.idle": "2022-11-08T22:43:53.264416Z",
     "shell.execute_reply": "2022-11-08T22:43:53.263973Z",
     "shell.execute_reply.started": "2022-11-08T22:43:53.259540Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_extra_data(data_x, dataset, correlation_threshold=0.05, max_features=100):\n",
    "    \n",
    "    list_argsort, list_correlations = pickle.load(open(f\"{dataset}_files/list_correlations_{dataset}.p\", \"rb\"))\n",
    "    \n",
    "    my_range = range(len(list_correlations))\n",
    "    \n",
    "    list_number_features = []\n",
    "    data_to_add = np.empty((data_x.shape[0], len(list_correlations)*max_features))\n",
    "    running_column_count = 0\n",
    "    for i in my_range:\n",
    "        data = data_x[:, list_argsort[i][list_correlations[i] < -correlation_threshold][:max_features]]\n",
    "        data_to_add[:, running_column_count:running_column_count+data.shape[1]] = data\n",
    "        \n",
    "        running_column_count += data.shape[1]\n",
    "        list_number_features.append(data.shape[1])\n",
    "        \n",
    "    return data_to_add[:, :np.sum(list_number_features)], list_number_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b9239e77-4466-4a50-ad13-950e5fb38fc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T22:43:53.471539Z",
     "iopub.status.busy": "2022-11-08T22:43:53.471037Z",
     "iopub.status.idle": "2022-11-08T22:43:53.474975Z",
     "shell.execute_reply": "2022-11-08T22:43:53.474518Z",
     "shell.execute_reply.started": "2022-11-08T22:43:53.471518Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_corr_columns(train_x, test_x, dataset, min_correlation, max_num_correlated_features):\n",
    "    \n",
    "    list_pca_scale_models = []\n",
    "\n",
    "    data_to_add_train, list_number_features = get_extra_data(train_x, dataset, min_correlation, max_num_correlated_features)\n",
    "    data_to_add_test, _ = get_extra_data(test_x, dataset, min_correlation, max_num_correlated_features)\n",
    "    indices_to_split =  np.cumsum(list_number_features)[:-1]\n",
    "    \n",
    "    return data_to_add_train, data_to_add_test, indices_to_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "60fc1cd4-c3de-4392-ae78-1bc0aed56926",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T22:43:53.613092Z",
     "iopub.status.busy": "2022-11-08T22:43:53.612824Z",
     "iopub.status.idle": "2022-11-08T22:43:53.617761Z",
     "shell.execute_reply": "2022-11-08T22:43:53.617320Z",
     "shell.execute_reply.started": "2022-11-08T22:43:53.613070Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_landmark_similarities(train_x, val_x, test_x, n_samples=1000):\n",
    "    \n",
    "    def stack_data(data, data_to_add):\n",
    "        cos_distance_matrix = sklearn.metrics.pairwise.cosine_similarity(data, data_to_add)\n",
    "        data = np.hstack((data, cos_distance_matrix))\n",
    "        # data = cos_distance_matrix\n",
    "        return data\n",
    "    \n",
    "    if n_samples is None:\n",
    "        data_to_stack = copy.deepcopy(test_x)\n",
    "    else:\n",
    "        random_indices = np.random.choice(test_x.shape[0], n_samples, replace=False)\n",
    "        data_to_stack = copy.deepcopy(test_x[random_indices, :])\n",
    "    \n",
    "    train_x = stack_data(train_x, data_to_stack)\n",
    "    val_x = stack_data(val_x, data_to_stack)\n",
    "    test_x = stack_data(test_x, data_to_stack)\n",
    "    \n",
    "    return train_x, val_x, test_x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9d1e5b-476d-4bcb-a032-273d887369da",
   "metadata": {},
   "source": [
    "# load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ff5ce1b8-2b4d-4a8e-a915-4c65a79ebaad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T22:43:54.021069Z",
     "iopub.status.busy": "2022-11-08T22:43:54.020781Z",
     "iopub.status.idle": "2022-11-08T22:43:54.024896Z",
     "shell.execute_reply": "2022-11-08T22:43:54.024419Z",
     "shell.execute_reply.started": "2022-11-08T22:43:54.021045Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def identify_constant_columns(train_x, test_x):\n",
    "    \n",
    "    constant_cols_list_train = train_x.columns[train_x.nunique() <= 1]\n",
    "    constant_cols_list_test = test_x.columns[test_x.nunique() <= 1]\n",
    "    constant_cols = set(list(constant_cols_list_train) + list(constant_cols_list_test))\n",
    "    \n",
    "    train_x = train_x.drop(columns=constant_cols)\n",
    "    test_x = test_x.drop(columns=constant_cols)\n",
    "            \n",
    "    return train_x, test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "74dfd2ea-2723-4d26-bbc5-d880fbd6ae29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T22:43:54.199885Z",
     "iopub.status.busy": "2022-11-08T22:43:54.199516Z",
     "iopub.status.idle": "2022-11-08T22:43:54.205059Z",
     "shell.execute_reply": "2022-11-08T22:43:54.204598Z",
     "shell.execute_reply.started": "2022-11-08T22:43:54.199862Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit_scale_data_and_pca(train_data, dataset):\n",
    "    \n",
    "    scaler = None\n",
    "    if dataset == \"citeseq\":\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(train_data)\n",
    "        train_data = scaler.transform(train_data).astype(np.float32)\n",
    "    \n",
    "    file_name = f\"{dataset}_files/pca_{dataset}.p\"\n",
    "    if os.path.exists(file_name):\n",
    "        pca = pickle.load(open(file_name, \"rb\"))\n",
    "    else:\n",
    "        raise ValueError(f\"pca file does not exist\") \n",
    "\n",
    "    train_data = pca.transform(train_data)\n",
    "        \n",
    "    scaler_pca = StandardScaler()\n",
    "    scaler_pca.fit(train_data)\n",
    "    train_data = scaler_pca.transform(train_data).astype(np.float32)\n",
    "    \n",
    "    return train_data, pca, scaler, scaler_pca\n",
    "\n",
    "def apply_scale_data_and_pca(data, scaler, pca, scaler_pca):\n",
    "    \n",
    "    if scaler is not None:\n",
    "        data = scaler.transform(data).astype(np.float32)\n",
    "    \n",
    "    data = pca.transform(data)\n",
    "    data = scaler_pca.transform(data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "faf909cf-0cc5-43b7-ab29-ded59b025fa3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T22:43:54.415162Z",
     "iopub.status.busy": "2022-11-08T22:43:54.414877Z",
     "iopub.status.idle": "2022-11-08T22:43:54.418595Z",
     "shell.execute_reply": "2022-11-08T22:43:54.418141Z",
     "shell.execute_reply.started": "2022-11-08T22:43:54.415138Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pca_keep_top_variance(data, variance_threshold):\n",
    "    \n",
    "    pca = PCA(data.shape[1])\n",
    "    pca.fit(data)\n",
    "    \n",
    "    k = np.where(np.cumsum(pca.explained_variance_ratio_) > variance_threshold)[0][0]\n",
    "    \n",
    "    return pca, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5f7faa33-c6cf-4cb2-8774-a23091b935f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T22:43:54.648950Z",
     "iopub.status.busy": "2022-11-08T22:43:54.648681Z",
     "iopub.status.idle": "2022-11-08T22:43:54.651839Z",
     "shell.execute_reply": "2022-11-08T22:43:54.651346Z",
     "shell.execute_reply.started": "2022-11-08T22:43:54.648927Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_metadata():\n",
    "    \n",
    "    metadata = pd.read_csv(\"/kaggle/input/open-problems-multimodal/metadata.csv\")\n",
    "\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "683d20e5-b7cd-40f2-bd68-3fe43356583f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T22:43:54.877812Z",
     "iopub.status.busy": "2022-11-08T22:43:54.877259Z",
     "iopub.status.idle": "2022-11-08T22:43:54.883036Z",
     "shell.execute_reply": "2022-11-08T22:43:54.882578Z",
     "shell.execute_reply.started": "2022-11-08T22:43:54.877776Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the paths to load the data\n",
    "\n",
    "def load_dataset(data_name):\n",
    "    \n",
    "    dir_path = \"/kaggle/input/open-problems-multimodal/\"\n",
    "\n",
    "    if data_name == \"citeseq\":\n",
    "        train_x_path = os.path.join(dir_path,\"train_cite_inputs.h5\")\n",
    "        train_y_path = os.path.join(dir_path,\"train_cite_targets.h5\")\n",
    "        test_x_path = os.path.join(dir_path,\"test_cite_inputs.h5\")\n",
    "        \n",
    "        train_x = pd.read_hdf(train_x_path)\n",
    "        train_y = pd.read_hdf(train_y_path)\n",
    "        test_x = pd.read_hdf(test_x_path)\n",
    "\n",
    "    elif data_name == \"multiome\":\n",
    "        \n",
    "        train_indices, test_indices, cols_name = pickle.load(open(\"multiome_files/index_train_test_cols.p\", \"rb\"))\n",
    "        \n",
    "        train_x = pickle.load(open(\"train_x_multi_svd.p\", \"rb\"))\n",
    "        train_y = scipy.sparse.load_npz(\"train_multi_targets_values.sparse.npz\").toarray()\n",
    "        test_x = pickle.load(open(\"test_x_multi_svd.p\", \"rb\"))\n",
    "        \n",
    "        train_x = pd.DataFrame(train_x, index=train_indices)\n",
    "        test_x = pd.DataFrame(test_x, index=test_indices)\n",
    "        train_y = pd.DataFrame(train_y, index=train_indices)\n",
    "        \n",
    "    else:\n",
    "        raise NameError(f\"{data_name} is not a valid name: choose between 'siteseq' and 'multiome'\")\n",
    "    \n",
    "    return train_x, train_y, test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "644bffd4-fa05-47d5-82dd-b875c26f9ca4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T22:43:55.095761Z",
     "iopub.status.busy": "2022-11-08T22:43:55.095484Z",
     "iopub.status.idle": "2022-11-08T22:43:55.099620Z",
     "shell.execute_reply": "2022-11-08T22:43:55.099177Z",
     "shell.execute_reply.started": "2022-11-08T22:43:55.095739Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_constant_targets(train_y):\n",
    "\n",
    "    constant_cols = np.all(train_y == train_y[0,:], axis = 0)\n",
    "    indices = [(i, train_y[0, i]) for i in range(len(constant_cols)) if constant_cols[i]]\n",
    "\n",
    "    train_y_modify = np.delete(train_y, [tup[0] for tup in indices], axis=1)\n",
    "\n",
    "    return train_y_modify, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f01fa6c0-ee79-4524-b84f-2913fcb33eed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T22:43:55.292245Z",
     "iopub.status.busy": "2022-11-08T22:43:55.291974Z",
     "iopub.status.idle": "2022-11-08T22:43:55.297825Z",
     "shell.execute_reply": "2022-11-08T22:43:55.297367Z",
     "shell.execute_reply.started": "2022-11-08T22:43:55.292223Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_donor_subet(train_x, test_x, metadata, dataset, split_by_donor=False):\n",
    "    \n",
    "    data_subset_dic = dict()\n",
    "    \n",
    "    if split_by_donor:\n",
    "        meta_data_donors = np.unique(meta_data[\"donor\"])\n",
    "        meta_subset_tech = meta_data[meta_data[\"technology\"] == dataset]\n",
    "\n",
    "        for donor in meta_data_donors:\n",
    "            donor_subset_train = meta_subset_tech[meta_subset_tech[\"donor\"] == donor][\"cell_id\"]\n",
    "            cell_id_in_common_train = donor_subset_train[donor_subset_train.isin(train_x.index)]\n",
    "\n",
    "            if np.sum(donor_subset_train) != 0:\n",
    "                donor_subset_test = meta_subset_tech[meta_subset_tech[\"donor\"] == donor][\"cell_id\"]\n",
    "                cell_id_in_common_test = donor_subset_test[donor_subset_test.isin(test_x.index)]\n",
    "                data_subset_dic[donor] = [cell_id_in_common_train, cell_id_in_common_train, cell_id_in_common_test]\n",
    "\n",
    "            else:\n",
    "                donor_subset_test = meta_subset_tech[meta_subset_tech[\"donor\"] == donor][\"cell_id\"]\n",
    "                cell_id_in_common_test = donor_subset_test[donor_subset_test.isin(test_x.index)]\n",
    "                data_subset_dic[donor] = [train_x.index, train_x.index, cell_id_in_common_test]\n",
    "    \n",
    "    else:\n",
    "        data_subset_dic[\"all_donor\"] = [train_x.index, train_x.index, test_x.index]\n",
    "            \n",
    "    return data_subset_dic\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1a248fe1-6404-439a-90b8-749caf6b1d82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T22:43:55.518285Z",
     "iopub.status.busy": "2022-11-08T22:43:55.518019Z",
     "iopub.status.idle": "2022-11-08T22:43:55.521600Z",
     "shell.execute_reply": "2022-11-08T22:43:55.521142Z",
     "shell.execute_reply.started": "2022-11-08T22:43:55.518263Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def select_indices_multiome(prediction_array):\n",
    "    \n",
    "    rows = pickle.load(open(\"multiome_files/cell_id_to_numbers.p\", \"rb\"))\n",
    "    cols = pickle.load(open(\"multiome_files/gene_id_to_numbers.p\", \"rb\"))\n",
    "    prediction_array = prediction_array[rows, cols]\n",
    "    \n",
    "    return prediction_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dc1482-959d-45b5-a6a5-38ee55a3f3b8",
   "metadata": {},
   "source": [
    "# get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b459e285-5a0a-447a-9e82-77f9113f83fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T22:43:55.955532Z",
     "iopub.status.busy": "2022-11-08T22:43:55.955256Z",
     "iopub.status.idle": "2022-11-08T22:43:55.958042Z",
     "shell.execute_reply": "2022-11-08T22:43:55.957601Z",
     "shell.execute_reply.started": "2022-11-08T22:43:55.955510Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7d8408f9-589b-49ea-9ef3-a1004ffb3fbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T22:43:56.141038Z",
     "iopub.status.busy": "2022-11-08T22:43:56.140780Z",
     "iopub.status.idle": "2022-11-08T22:43:56.143613Z",
     "shell.execute_reply": "2022-11-08T22:43:56.143171Z",
     "shell.execute_reply.started": "2022-11-08T22:43:56.141015Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = \"citeseq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "49235f38-4907-4fcd-8e96-4366db4127a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T22:43:56.363314Z",
     "iopub.status.busy": "2022-11-08T22:43:56.363046Z",
     "iopub.status.idle": "2022-11-08T22:44:46.929452Z",
     "shell.execute_reply": "2022-11-08T22:44:46.928898Z",
     "shell.execute_reply.started": "2022-11-08T22:43:56.363293Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_x, train_y, test_x = load_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fb7f2a69-be60-4594-8b25-085161e7dfac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T22:44:46.930845Z",
     "iopub.status.busy": "2022-11-08T22:44:46.930592Z",
     "iopub.status.idle": "2022-11-08T22:45:21.906059Z",
     "shell.execute_reply": "2022-11-08T22:45:21.905527Z",
     "shell.execute_reply.started": "2022-11-08T22:44:46.930822Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if dataset == \"citeseq\":\n",
    "    train_x, test_x = identify_constant_columns(train_x, test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "832cfc58-44c3-4049-a837-63f4c77dc8a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T22:45:21.907114Z",
     "iopub.status.busy": "2022-11-08T22:45:21.906884Z",
     "iopub.status.idle": "2022-11-08T22:45:22.088309Z",
     "shell.execute_reply": "2022-11-08T22:45:22.087797Z",
     "shell.execute_reply.started": "2022-11-08T22:45:21.907093Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "meta_data = load_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9866f278-f068-4b07-8b3c-f718aa9471b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T22:45:22.089820Z",
     "iopub.status.busy": "2022-11-08T22:45:22.089574Z",
     "iopub.status.idle": "2022-11-08T22:45:22.140134Z",
     "shell.execute_reply": "2022-11-08T22:45:22.139635Z",
     "shell.execute_reply.started": "2022-11-08T22:45:22.089798Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "_, indices = remove_constant_targets(np.array(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b9eef6-a5dc-4de7-9a37-61957c949dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "16ea55f4-d5e5-4fad-a498-f735ddc28e86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T22:45:22.141184Z",
     "iopub.status.busy": "2022-11-08T22:45:22.140941Z",
     "iopub.status.idle": "2022-11-08T22:45:22.165172Z",
     "shell.execute_reply": "2022-11-08T22:45:22.164723Z",
     "shell.execute_reply.started": "2022-11-08T22:45:22.141161Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "meta_multiome = meta_data[meta_data[\"technology\"] == dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015ddffb-da08-4382-bd37-735457fc2943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a699a718-97b9-48c4-aefa-35e0c27ed2e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8eac9b-5f6d-4da0-8c40-ce9a59017e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "670cd5bc-4de1-4051-9435-d6195d6c5f60",
   "metadata": {},
   "source": [
    "# Pytorch utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b74b5d88-89c4-48e6-ab90-c2283bb3f30c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T22:45:22.166093Z",
     "iopub.status.busy": "2022-11-08T22:45:22.165883Z",
     "iopub.status.idle": "2022-11-08T22:45:22.171089Z",
     "shell.execute_reply": "2022-11-08T22:45:22.170655Z",
     "shell.execute_reply.started": "2022-11-08T22:45:22.166073Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def torch_corrcoef(preds, target):\n",
    "    \n",
    "    metric = PearsonCorrCoef().to(device)\n",
    "    \n",
    "    output = torch.empty(size=(preds.shape[0],)).to(device)\n",
    "    for i in range(preds.shape[0]):\n",
    "        score = metric(preds[i], target[i])\n",
    "        output[i] = score\n",
    "    \n",
    "    return output.mean()\n",
    "\n",
    "def corrcoef(preds, target):\n",
    "    \n",
    "    pred_centred = preds-torch.unsqueeze(torch.mean(preds, 1), 1)\n",
    "    target_centred = target-torch.unsqueeze(torch.mean(target, 1), 1)\n",
    "    \n",
    "    pred_std = torch.unsqueeze(torch.sqrt(torch.mean(pred_centred**2, 1)), 1)\n",
    "    target_std = torch.unsqueeze(torch.sqrt(torch.mean(target_centred**2, 1)), 1)\n",
    "    \n",
    "    corr_torch = pred_centred*target_centred/(pred_std*target_std)\n",
    "\n",
    "    return corr_torch.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "163135f5-b339-48e5-8cd2-8b05cf47a890",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T22:45:22.172148Z",
     "iopub.status.busy": "2022-11-08T22:45:22.171797Z",
     "iopub.status.idle": "2022-11-08T22:45:22.184907Z",
     "shell.execute_reply": "2022-11-08T22:45:22.184480Z",
     "shell.execute_reply.started": "2022-11-08T22:45:22.172127Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training loop for each epoch\n",
    "\n",
    "def train(dataloader, model, loss_fn, loss, optimizer, device):\n",
    "    \n",
    "    num_batches = len(dataloader)\n",
    "    model.train()\n",
    "    loss_list = []\n",
    "    corr_list = []\n",
    "    \n",
    "    for X, y in dataloader:\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        if (loss == \"mse\") or (loss == \"mae\"):\n",
    "            train_loss = loss_fn(pred, y)\n",
    "        elif loss == \"huber\":\n",
    "            train_loss = loss_fn(pred, y)\n",
    "        elif (loss == \"cosine\") or (loss == \"corrcoef\") or (loss == \"torchcorrcoef\"):\n",
    "            train_loss = loss_fn(pred, y)*-1\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        loss_list.append(train_loss.item())\n",
    "        \n",
    "        pred = pred.cpu().detach().numpy()\n",
    "        y = y.cpu().detach().numpy()\n",
    "        \n",
    "        corr_list.append([pearsonr(pred[i], y[i])[0] for i in range(pred.shape[0])])\n",
    "    \n",
    "    loss = np.mean(loss_list)\n",
    "    corr = np.mean(np.concatenate(corr_list))\n",
    "    \n",
    "    return loss, corr\n",
    "\n",
    "\n",
    "# validation loop for each epoch\n",
    "def val(dataloader, model, loss_fn, loss, device):\n",
    "    \n",
    "    pred_val_list = []\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    loss_list = []\n",
    "    corr_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            \n",
    "            # Compute prediction error\n",
    "            #pred = torch.from_numpy(np.mean([model(X).cpu().detach().numpy() for _ in range(100)], axis=0)).to(device)\n",
    "            pred = model(X)\n",
    "            \n",
    "            if (loss == \"mse\") or (loss == \"mae\"):\n",
    "                val_loss = loss_fn(pred, y)\n",
    "            elif loss == \"huber\":\n",
    "                val_loss = loss_fn(pred, y)\n",
    "            elif (loss == \"cosine\") or (loss == \"corrcoef\") or (loss == \"torchcorrcoef\"):\n",
    "                val_loss = loss_fn(pred, y)*-1\n",
    "                \n",
    "            loss_list.append(val_loss.item())\n",
    "            \n",
    "            pred = pred.cpu().detach().numpy()\n",
    "            if pred.shape[1] > 20000:\n",
    "                for i in range(pred.shape[0]):\n",
    "                    zero_value = np.mean(pred[i][[ind[0] for ind in indices]])\n",
    "                    pred[i][pred[i] < zero_value] = zero_value\n",
    "            \n",
    "            y = y.cpu().detach().numpy()\n",
    "            pred_val_list.append(pred)\n",
    "            \n",
    "            corr_list.append([pearsonr(pred[i], y[i])[0] for i in range(pred.shape[0])])\n",
    "\n",
    "    loss = np.mean(loss_list)\n",
    "    corr = np.mean(np.concatenate(corr_list))\n",
    "    \n",
    "    return loss, corr, pred_val_list\n",
    "\n",
    "\n",
    "# make predictions on the test set (dataloader is only made of x)\n",
    "def test(dataloader, model, device, num_eval=100, d=False):\n",
    "    \n",
    "    pred_list = []\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X in dataloader:\n",
    "            \n",
    "            if d:\n",
    "                pred = np.mean([model(X).cpu().detach().numpy() for _ in range(num_eval)], axis=0)\n",
    "            else:\n",
    "                pred = model(X)\n",
    "                pred = pred.cpu().detach().numpy()\n",
    "                \n",
    "            if pred.shape[1] > 20000:\n",
    "                for i in range(pred.shape[0]):\n",
    "                    zero_value = np.mean(pred[i][[ind[0] for ind in indices]])\n",
    "                    pred[i][pred[i] < zero_value] = zero_value\n",
    "                    \n",
    "            pred_list.append(pred)\n",
    "    \n",
    "    return pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "25b5cbc8-1b5f-4e89-a3eb-1524c279bf81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T22:45:22.185774Z",
     "iopub.status.busy": "2022-11-08T22:45:22.185562Z",
     "iopub.status.idle": "2022-11-08T22:45:22.191157Z",
     "shell.execute_reply": "2022-11-08T22:45:22.190734Z",
     "shell.execute_reply.started": "2022-11-08T22:45:22.185755Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataset class that loads the data and prepare it for the pytorch dataloader\n",
    "\n",
    "class CompetitionDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_tuple, mode='train'):\n",
    "        self.mode = mode\n",
    "        \n",
    "        if self.mode == \"train\":\n",
    "            # assert len(data_tuple) == 2, \"`data_tuple` should have lenght 2\"\n",
    "            data_x, data_y = data_tuple\n",
    "        elif self.mode == \"test\":\n",
    "            # assert len(data_tuple) == 1, \"`data_tuple` should have length 1\"\n",
    "            data_x = data_tuple[0]\n",
    "        else:\n",
    "            raise NameError(f\"{self.mode} is not a valid mode: choose between 'train' and 'test'\")\n",
    "\n",
    "        self.filenames = dict()\n",
    "        self.filenames['x'] = data_x\n",
    "        \n",
    "        if self.mode == \"train\":\n",
    "            self.filenames['y'] = data_y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch = dict()\n",
    "        \n",
    "        batch['x'] = torch.from_numpy(self.filenames['x'][index])\n",
    "        \n",
    "        if self.mode == \"train\":\n",
    "            batch['y'] = torch.from_numpy(self.filenames['y'][index]).to(device)\n",
    "            return batch['x'].to(device), batch['y']\n",
    "        else:\n",
    "            return batch['x'].to(device)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.filenames['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "68937ca6-67cf-479d-b9eb-14ae28e70f8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T22:45:22.191953Z",
     "iopub.status.busy": "2022-11-08T22:45:22.191760Z",
     "iopub.status.idle": "2022-11-08T22:45:22.196830Z",
     "shell.execute_reply": "2022-11-08T22:45:22.196386Z",
     "shell.execute_reply.started": "2022-11-08T22:45:22.191934Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pytorch_dataset_and_dataloader(tr_x, tr_y, val_x, val_y, batch_size = 256, mode = \"train\"):\n",
    "\n",
    "    train_dataset = CompetitionDataset((tr_x, tr_y), mode)\n",
    "    val_dataset = CompetitionDataset((val_x, val_y), mode) # here \"train\" is also used for validation\n",
    "    \n",
    "    train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size, drop_last=False)\n",
    "    val_dataloader = DataLoader(val_dataset, shuffle=False, batch_size=batch_size, drop_last=False)\n",
    "    \n",
    "    return train_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e2650a-f4ae-4599-a74b-c880ed61e50d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ba34393-bbb4-497b-9b3d-2e895ad41ca9",
   "metadata": {},
   "source": [
    "# Pytorch simple MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "76d0ae02-9b3d-4ea0-85a0-e99153573780",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T22:45:22.198376Z",
     "iopub.status.busy": "2022-11-08T22:45:22.198181Z",
     "iopub.status.idle": "2022-11-08T22:45:22.201363Z",
     "shell.execute_reply": "2022-11-08T22:45:22.200953Z",
     "shell.execute_reply.started": "2022-11-08T22:45:22.198357Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def obtain_model_dropout(model):\n",
    "    \n",
    "    new_model =  NeuralNetwork(n_shared_hidden_layers, shared_hidden_size_list, n_non_shared_hidden_layers, \n",
    "                              non_shared_hidden_size_list, drop, n_components_to_keep, indices_to_split, \n",
    "                              output_size, n_components_to_keep, True).to(device)\n",
    "    \n",
    "    new_model.parameters = model.parameters\n",
    "    \n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d0b88c98-b03c-40dd-bfe0-51511723dc15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T22:45:22.202152Z",
     "iopub.status.busy": "2022-11-08T22:45:22.201961Z",
     "iopub.status.idle": "2022-11-08T22:45:22.207475Z",
     "shell.execute_reply": "2022-11-08T22:45:22.207077Z",
     "shell.execute_reply.started": "2022-11-08T22:45:22.202133Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DropoutAlwaysActivated(dropout._DropoutNd):\n",
    "\n",
    "    def forward(self, x):\n",
    "        return functional.dropout(x, self.p, True, self.inplace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1664da54-c420-4d76-9c33-1cb0361cbcdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T22:45:22.208264Z",
     "iopub.status.busy": "2022-11-08T22:45:22.208073Z",
     "iopub.status.idle": "2022-11-08T22:45:22.212442Z",
     "shell.execute_reply": "2022-11-08T22:45:22.212031Z",
     "shell.execute_reply.started": "2022-11-08T22:45:22.208245Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class custom_layer_input_dropout(nn.Module):\n",
    "    def __init__(self, input_size, dropout_p):\n",
    "        super().__init__()\n",
    "        self.dropout_p = dropout_p\n",
    "        self.input_size = input_size\n",
    "        self.identity = nn.Identity(self.input_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.identity(x)\n",
    "        \n",
    "        self.training = True\n",
    "        if self.training:\n",
    "            drop_out_values = (np.random.uniform(0.0, 1.0, self.input_size) < self.dropout_p).astype(np.float32)\n",
    "            drop_out_values *= (1/self.dropout_p)\n",
    "            x = x*torch.from_numpy(drop_out_values).to(device)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d64bc64c-1a4b-4385-ad54-671f6b6ee650",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T22:45:22.213439Z",
     "iopub.status.busy": "2022-11-08T22:45:22.213145Z",
     "iopub.status.idle": "2022-11-08T22:45:22.224115Z",
     "shell.execute_reply": "2022-11-08T22:45:22.223718Z",
     "shell.execute_reply.started": "2022-11-08T22:45:22.213418Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, n_shared_hidden_layers, shared_hidden_size_list, n_non_shared_hidden_layers, non_shared_hidden_size_list, \n",
    "                 drop, shared_input_size, indices_to_split, output_size, n_components_to_keep, dropout_montecarlo = False):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        \n",
    "        assert len(shared_hidden_size_list) == n_shared_hidden_layers, f\"`hidden_size_list` should have length {n_shared_hidden_layers}\"\n",
    "        assert len(non_shared_hidden_size_list) == n_non_shared_hidden_layers, f\"`hidden_size_list` should have length {n_non_shared_hidden_layers}\"\n",
    "        \n",
    "        self.n_shared_hidden_layers = n_shared_hidden_layers\n",
    "        self.shared_hidden_size = shared_hidden_size_list\n",
    "        self.n_non_shared_hidden_layers = n_non_shared_hidden_layers\n",
    "        self.non_shared_hidden_size = non_shared_hidden_size_list\n",
    "        self.drop = drop\n",
    "        self.shared_input_size = shared_input_size\n",
    "        self.indices_to_split = indices_to_split\n",
    "        self.output_size = output_size\n",
    "        self.input_size = n_components_to_keep\n",
    "        self.dropout_montecarlo = dropout_montecarlo\n",
    "        \n",
    "        # explained_variance = pickle.load(open(\"multiome_files/pca_multiome.p\", \"rb\")).explained_variance_[:self.input_size]\n",
    "        # p = 0.8\n",
    "        # self.input_dropout = ((explained_variance - np.min(explained_variance))/(np.max(explained_variance) - np.min(explained_variance)))*(1-p)+p\n",
    "        # self.custom_layer_input_dropout = custom_layer_input_dropout(self.input_size, self.input_dropout)\n",
    "        \n",
    "        # hidden layers\n",
    "        self.shared_hidden_layers_list = nn.ModuleList()\n",
    "        for l in range(self.n_shared_hidden_layers):\n",
    "            self.shared_hidden_layers_list.append(nn.LazyLinear(self.shared_hidden_size[l]))\n",
    "            self.shared_hidden_layers_list.append(nn.SELU())\n",
    "            if dropout_montecarlo:\n",
    "                self.shared_hidden_layers_list.append(DropoutAlwaysActivated(self.drop))\n",
    "            else:\n",
    "                self.shared_hidden_layers_list.append(nn.Dropout(self.drop))\n",
    "            self.shared_hidden_layers_list.append(nn.BatchNorm1d(self.shared_hidden_size[l]))\n",
    "            \n",
    "        self.shared_hidden_layers_list = nn.Sequential(*self.shared_hidden_layers_list)\n",
    "        \n",
    "        if n_non_shared_hidden_layers > 0:\n",
    "            self.non_shared_concat = nn.ModuleList(nn.ModuleList() for _ in range(self.output_size))\n",
    "            for i in range(self.output_size):\n",
    "                for l in range(self.n_non_shared_hidden_layers):\n",
    "                    self.non_shared_concat[i].append(nn.LazyLinear(self.non_shared_hidden_size[l]))\n",
    "                    self.non_shared_concat[i].append(nn.SELU())\n",
    "                    self.non_shared_concat[i].append(nn.Dropout(self.drop))\n",
    "                    self.non_shared_concat[i].append(nn.BatchNorm1d(self.non_shared_hidden_size[l]))\n",
    "\n",
    "                self.non_shared_concat[i].append(nn.LazyLinear(1))\n",
    "                self.non_shared_concat[i] = nn.Sequential(*self.non_shared_concat[i])\n",
    "        else:\n",
    "            self.output_layer = nn.LazyLinear(self.output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # x = self.custom_layer_input_dropout(x)\n",
    "        \n",
    "        if indices_to_split is not None:\n",
    "            x_non_shared = np.split(x[:, self.shared_input_size:], self.indices_to_split, 1)\n",
    "            x = x[:, :self.shared_input_size]\n",
    "        \n",
    "        shared_x = self.shared_hidden_layers_list(x)\n",
    "        \n",
    "        if n_non_shared_hidden_layers > 0:\n",
    "            output = torch.empty(size=(shared_x.shape[0], self.output_size)).to(\"cuda\")\n",
    "            for i in range(self.output_size):\n",
    "                if indices_to_split is not None:\n",
    "                    not_shared_x = torch.hstack((shared_x, x_non_shared[i]))\n",
    "                else:\n",
    "                    not_shared_x = shared_x\n",
    "                not_shared_x = self.non_shared_concat[i](not_shared_x)\n",
    "\n",
    "                output[:, i] = torch.squeeze(not_shared_x)\n",
    "        \n",
    "        else:\n",
    "            output = self.output_layer(shared_x)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0c44ed14-c9b3-4381-92f8-e61dffa8eb92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T22:45:22.224929Z",
     "iopub.status.busy": "2022-11-08T22:45:22.224734Z",
     "iopub.status.idle": "2022-11-08T22:45:22.230095Z",
     "shell.execute_reply": "2022-11-08T22:45:22.229696Z",
     "shell.execute_reply.started": "2022-11-08T22:45:22.224910Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_components_to_keep = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "761681b2-d86b-4f12-82c6-f21ad5328dd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T22:45:22.230876Z",
     "iopub.status.busy": "2022-11-08T22:45:22.230670Z",
     "iopub.status.idle": "2022-11-08T22:45:22.235361Z",
     "shell.execute_reply": "2022-11-08T22:45:22.234960Z",
     "shell.execute_reply.started": "2022-11-08T22:45:22.230857Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_by_donor = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c88c17f3-4029-4485-86c7-ebbdc8759cb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T22:45:22.236123Z",
     "iopub.status.busy": "2022-11-08T22:45:22.235935Z",
     "iopub.status.idle": "2022-11-08T22:45:22.240024Z",
     "shell.execute_reply": "2022-11-08T22:45:22.239617Z",
     "shell.execute_reply.started": "2022-11-08T22:45:22.236105Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "add_correlated_columns = True\n",
    "\n",
    "min_correlation = 0.1\n",
    "max_num_correlated_features = 50\n",
    "indices_to_split = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f96102ba-2079-4564-a585-246bc6cf2590",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T22:45:22.256368Z",
     "iopub.status.busy": "2022-11-08T22:45:22.256177Z",
     "iopub.status.idle": "2022-11-08T22:45:22.260146Z",
     "shell.execute_reply": "2022-11-08T22:45:22.259750Z",
     "shell.execute_reply.started": "2022-11-08T22:45:22.256349Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# network parameters\n",
    "output_size = train_y.shape[1]\n",
    "\n",
    "n_shared_hidden_layers = 3\n",
    "n_non_shared_hidden_layers = 1\n",
    "\n",
    "drop = 0.5\n",
    "\n",
    "shared_hidden_size_list = [1024, 1024, 1024] \n",
    "non_shared_hidden_size_list = [512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6c74c04a-dac2-4aee-be3b-f169b8bfcc33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T22:45:22.246062Z",
     "iopub.status.busy": "2022-11-08T22:45:22.245871Z",
     "iopub.status.idle": "2022-11-08T22:45:22.250675Z",
     "shell.execute_reply": "2022-11-08T22:45:22.250281Z",
     "shell.execute_reply.started": "2022-11-08T22:45:22.246043Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss = \"corrcoef\"\n",
    "\n",
    "num_folds = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2adc00d9-7376-4d0b-857b-66d584ca8698",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T00:04:47.734229Z",
     "iopub.status.busy": "2022-11-09T00:04:47.733945Z",
     "iopub.status.idle": "2022-11-09T00:04:47.737128Z",
     "shell.execute_reply": "2022-11-09T00:04:47.736693Z",
     "shell.execute_reply.started": "2022-11-09T00:04:47.734206Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "batch_size = 256\n",
    "n_epoch = 1\n",
    "early_stopping_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3444b9c7-1d65-4610-a50b-e2ee885df0ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3108ee1b-4be2-453e-b376-610a538a439e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b13e3b4f-b734-4428-82cf-9b855efb09f4",
   "metadata": {},
   "source": [
    "# cross validation and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fc361619-e454-486c-9e9b-72806347ed16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T22:45:28.184192Z",
     "iopub.status.busy": "2022-11-08T22:45:28.183899Z",
     "iopub.status.idle": "2022-11-08T22:45:28.187215Z",
     "shell.execute_reply": "2022-11-08T22:45:28.186707Z",
     "shell.execute_reply.started": "2022-11-08T22:45:28.184166Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_subset_dic = get_donor_subet(train_x, test_x, meta_data, dataset, split_by_donor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5366ec45-8a73-47da-84fa-d87cd10e20bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T22:45:28.749965Z",
     "iopub.status.busy": "2022-11-08T22:45:28.749675Z",
     "iopub.status.idle": "2022-11-08T23:30:44.571475Z",
     "shell.execute_reply": "2022-11-08T23:30:44.570969Z",
     "shell.execute_reply.started": "2022-11-08T22:45:28.749940Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing for donor all_donor\n",
      "computing for fold number 1\n",
      "n for training set: 63889, n for validation set: 7099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/saturn/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator PCA from version 1.1.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/saturn/lib/python3.9/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTER LOOP epoch 0\n",
      "training loss: -0.7451705948840827, corr train: 0.7449323183720531, validation_loss: -0.89251266845635, corr val: 0.8928068192052483\n",
      "OUTER LOOP epoch 1\n",
      "training loss: -0.8845920932292938, corr train: 0.884609153500778, validation_loss: -0.8965694989476886, corr val: 0.8968598606395376\n",
      "OUTER LOOP epoch 2\n",
      "training loss: -0.8896425764560699, corr train: 0.8896518871446821, validation_loss: -0.8978621533938816, corr val: 0.8981496399845107\n",
      "OUTER LOOP epoch 3\n",
      "training loss: -0.8921798818111419, corr train: 0.8921797383824087, validation_loss: -0.8992516355855125, corr val: 0.8995345454943495\n",
      "OUTER LOOP epoch 4\n",
      "training loss: -0.8937819457054138, corr train: 0.8937799993862684, validation_loss: -0.89969944528171, corr val: 0.8999779418398287\n",
      "OUTER LOOP epoch 5\n",
      "training loss: -0.8949581780433655, corr train: 0.8949710647269145, validation_loss: -0.9003759750298092, corr val: 0.9006496908739977\n",
      "OUTER LOOP epoch 6\n",
      "training loss: -0.8958580868244171, corr train: 0.8958525743112536, validation_loss: -0.9009164316313607, corr val: 0.9011882285839836\n",
      "OUTER LOOP epoch 7\n",
      "training loss: -0.8966279079914093, corr train: 0.8966161559650124, validation_loss: -0.9012630986315864, corr val: 0.9015327454280642\n",
      "OUTER LOOP epoch 8\n",
      "training loss: -0.8971772763729096, corr train: 0.8971617343255276, validation_loss: -0.9017835557460785, corr val: 0.9020522121913946\n",
      "OUTER LOOP epoch 9\n",
      "training loss: -0.8978148682117462, corr train: 0.8978258466941483, validation_loss: -0.9018302687576839, corr val: 0.9020962920694001\n",
      "OUTER LOOP epoch 10\n",
      "training loss: -0.8982279307842255, corr train: 0.8982327899092664, validation_loss: -0.9022155787263598, corr val: 0.9024850517245092\n",
      "OUTER LOOP epoch 11\n",
      "training loss: -0.8986210174560547, corr train: 0.8986223449140398, validation_loss: -0.9023013966424125, corr val: 0.9025684676527196\n",
      "OUTER LOOP epoch 12\n",
      "training loss: -0.8989646189212799, corr train: 0.8989588545034792, validation_loss: -0.902610216821943, corr val: 0.9028740514741846\n",
      "OUTER LOOP epoch 13\n",
      "training loss: -0.8992644309997558, corr train: 0.8992603216478413, validation_loss: -0.9026733934879303, corr val: 0.9029352354669823\n",
      "OUTER LOOP epoch 14\n",
      "training loss: -0.899510407447815, corr train: 0.8995110086842597, validation_loss: -0.902789124420711, corr val: 0.9030491088488565\n",
      "OUTER LOOP epoch 15\n",
      "training loss: -0.8998316731452942, corr train: 0.8998347663960646, validation_loss: -0.9030750628028598, corr val: 0.9033360202610272\n",
      "OUTER LOOP epoch 16\n",
      "training loss: -0.9000285127162934, corr train: 0.9000153172032109, validation_loss: -0.9030866878373283, corr val: 0.9033487268416339\n",
      "OUTER LOOP epoch 17\n",
      "training loss: -0.900274270772934, corr train: 0.9002618338869537, validation_loss: -0.903113665325301, corr val: 0.9033777561223378\n",
      "OUTER LOOP epoch 18\n",
      "training loss: -0.9006220443248749, corr train: 0.9006274950365332, validation_loss: -0.9033309498003551, corr val: 0.9035948944494276\n",
      "OUTER LOOP epoch 19\n",
      "training loss: -0.9006535670757294, corr train: 0.9006622220299484, validation_loss: -0.9033969640731812, corr val: 0.9036579666734519\n",
      "OUTER LOOP epoch 20\n",
      "training loss: -0.9009095788002014, corr train: 0.9008958069812307, validation_loss: -0.9035211397068841, corr val: 0.9037779136631806\n",
      "OUTER LOOP epoch 21\n",
      "training loss: -0.9011511714458466, corr train: 0.9011430671317082, validation_loss: -0.9035850827183042, corr val: 0.9038413967559942\n",
      "OUTER LOOP epoch 22\n",
      "training loss: -0.9013128638267517, corr train: 0.901328275933555, validation_loss: -0.9034952606473651, corr val: 0.9037538876174337\n",
      "OUTER LOOP epoch 23\n",
      "training loss: -0.9014166400432587, corr train: 0.9014130122410446, validation_loss: -0.9036713391542435, corr val: 0.9039273626926694\n",
      "OUTER LOOP epoch 24\n",
      "training loss: -0.9016473195552825, corr train: 0.9016458771469705, validation_loss: -0.903606482914516, corr val: 0.9038651188057031\n",
      "OUTER LOOP epoch 25\n",
      "training loss: -0.9016839458942413, corr train: 0.9016836370397631, validation_loss: -0.903801611491612, corr val: 0.9040565500627419\n",
      "OUTER LOOP epoch 26\n",
      "training loss: -0.9019612982273102, corr train: 0.9019689023340102, validation_loss: -0.9038466406720025, corr val: 0.9041043654164921\n",
      "OUTER LOOP epoch 27\n",
      "training loss: -0.9022035808563232, corr train: 0.9021969944152113, validation_loss: -0.9038071653672627, corr val: 0.9040648242585207\n",
      "OUTER LOOP epoch 28\n",
      "training loss: -0.9023573622703552, corr train: 0.9023555077091726, validation_loss: -0.9038512387445995, corr val: 0.9041087024014866\n",
      "OUTER LOOP epoch 29\n",
      "training loss: -0.9025068774223327, corr train: 0.9024999728129327, validation_loss: -0.9038876805986676, corr val: 0.9041456087598712\n",
      "OUTER LOOP epoch 30\n",
      "training loss: -0.902648647069931, corr train: 0.9026374653212048, validation_loss: -0.9039127784115928, corr val: 0.9041699282825056\n",
      "OUTER LOOP epoch 31\n",
      "training loss: -0.9028073287010193, corr train: 0.9028170587893228, validation_loss: -0.9038393752915519, corr val: 0.9040972455245108\n",
      "OUTER LOOP epoch 32\n",
      "training loss: -0.9028884963989258, corr train: 0.902900716116738, validation_loss: -0.9039679318666458, corr val: 0.904224459801202\n",
      "OUTER LOOP epoch 33\n",
      "training loss: -0.9031216976642609, corr train: 0.9031272602670537, validation_loss: -0.9040177528347287, corr val: 0.9042768066187243\n",
      "OUTER LOOP epoch 34\n",
      "training loss: -0.9032419815063476, corr train: 0.9032572035557566, validation_loss: -0.9039580247231892, corr val: 0.9042173637956107\n",
      "OUTER LOOP epoch 35\n",
      "training loss: -0.9034042189121246, corr train: 0.9034135756145769, validation_loss: -0.9039130764348167, corr val: 0.904169638978987\n",
      "OUTER LOOP epoch 36\n",
      "training loss: -0.9035109000205994, corr train: 0.9035055602847263, validation_loss: -0.9040154580559049, corr val: 0.9042764004251957\n",
      "OUTER LOOP epoch 37\n",
      "training loss: -0.9036819415092469, corr train: 0.9036744297661659, validation_loss: -0.9040736705064774, corr val: 0.9043285623696049\n",
      "OUTER LOOP epoch 38\n",
      "training loss: -0.9038676428794861, corr train: 0.9038584934479974, validation_loss: -0.904101060969489, corr val: 0.904353598082512\n",
      "OUTER LOOP epoch 39\n",
      "training loss: -0.9039740898609161, corr train: 0.9039741905197396, validation_loss: -0.9039361434323447, corr val: 0.9041921453778521\n",
      "OUTER LOOP epoch 40\n",
      "training loss: -0.9041123702526093, corr train: 0.9041130445440878, validation_loss: -0.9040306763989585, corr val: 0.9042860116870122\n",
      "OUTER LOOP epoch 41\n",
      "training loss: -0.9043077554702759, corr train: 0.9043054606975739, validation_loss: -0.9041020338024411, corr val: 0.9043553827602946\n",
      "OUTER LOOP epoch 42\n",
      "training loss: -0.9043791127204895, corr train: 0.9043828280137041, validation_loss: -0.904050316129412, corr val: 0.9043053625750485\n",
      "OUTER LOOP epoch 43\n",
      "training loss: -0.9045408735275269, corr train: 0.9045327283013821, validation_loss: -0.9040222487279347, corr val: 0.904274431725535\n",
      "OUTER LOOP epoch 44\n",
      "training loss: -0.9047807083129883, corr train: 0.9047658046858729, validation_loss: -0.9040292714323316, corr val: 0.9042844258402364\n",
      "OUTER LOOP epoch 45\n",
      "training loss: -0.904865629196167, corr train: 0.9048589460602098, validation_loss: -0.9040019405739648, corr val: 0.9042538111781621\n",
      "OUTER LOOP epoch 46\n",
      "training loss: -0.9048947944641114, corr train: 0.9048982416429383, validation_loss: -0.9040621902261462, corr val: 0.9043158887118089\n",
      "OUTER LOOP epoch 47\n",
      "training loss: -0.9050402464866638, corr train: 0.905038558799533, validation_loss: -0.9040360706193107, corr val: 0.9042906521574444\n",
      "OUTER LOOP epoch 48\n",
      "training loss: -0.9051795382499694, corr train: 0.9051804965036331, validation_loss: -0.9040424057415554, corr val: 0.9042991913067733\n",
      "OUTER LOOP epoch 49\n",
      "training loss: -0.9052646670341492, corr train: 0.9052691356979384, validation_loss: -0.9040247968264988, corr val: 0.9042828267649073\n",
      "OUTER LOOP epoch 50\n",
      "training loss: -0.9054349493980408, corr train: 0.9054378421668182, validation_loss: -0.9039148028407779, corr val: 0.9041717710261078\n",
      "Computing for the SWA model. validation_loss: -0.9043670232806887, corr val: 0.9046208614118285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/saturn/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:239: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/saturn/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# cross validation and inference\n",
    "\n",
    "test_predictions_dic = dict()\n",
    "\n",
    "for k in data_subset_dic.keys():\n",
    "    test_predictions_dic[k] = []\n",
    "    \n",
    "    print(f\"computing for donor {k}\")\n",
    "    \n",
    "    ind_tr_x, in_tr_y, ind_test_x = data_subset_dic[k]\n",
    "    \n",
    "    subset_train_x = np.array(train_x.loc[ind_tr_x])\n",
    "    subset_train_y = np.array(train_y.loc[in_tr_y])\n",
    "    subset_test_x = np.array(test_x.loc[ind_test_x])\n",
    "\n",
    "    if add_correlated_columns and dataset == \"citeseq\":\n",
    "        data_to_add_train, data_to_add_test, indices_to_split = add_corr_columns(subset_train_x, subset_test_x, \n",
    "                                                                                 dataset, min_correlation, max_num_correlated_features)\n",
    "    \n",
    "    fold_number = 0\n",
    "    for train_index, val_index in list(KFold(num_folds, shuffle=True, random_state=0).split(subset_train_x))[:]:\n",
    "        print(f\"computing for fold number {fold_number+1}\")\n",
    "        print(f\"n for training set: {train_index.shape[0]}, n for validation set: {val_index.shape[0]}\")\n",
    "\n",
    "        tr_x, tr_y = subset_train_x[train_index], subset_train_y[train_index]\n",
    "        val_x, val_y = subset_train_x[val_index], subset_train_y[val_index]\n",
    "        te_x = copy.deepcopy(subset_test_x)\n",
    "        \n",
    "        if dataset == \"citeseq\":\n",
    "            tr_x, pca_model, scaler_org_data, scaler_pca_data = fit_scale_data_and_pca(tr_x, dataset)\n",
    "            val_x = apply_scale_data_and_pca(val_x, scaler_org_data, pca_model, scaler_pca_data)\n",
    "            te_x = apply_scale_data_and_pca(te_x, scaler_org_data, pca_model, scaler_pca_data)\n",
    "            \n",
    "        tr_x = tr_x[:, :n_components_to_keep]\n",
    "        val_x = val_x[:, :n_components_to_keep]\n",
    "        te_x = te_x[:, :n_components_to_keep]\n",
    "    \n",
    "        tr_x, val_x, te_x = add_landmark_similarities(tr_x, val_x, te_x, 2000)\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(tr_x)\n",
    "        tr_x = scaler.transform(tr_x).astype(np.float32)\n",
    "        val_x = scaler.transform(val_x).astype(np.float32)\n",
    "        te_x = scaler.transform(te_x).astype(np.float32)\n",
    "\n",
    "        if add_correlated_columns and dataset == \"citeseq\":\n",
    "            important_subset_tr = copy.deepcopy(data_to_add_train)[train_index]\n",
    "            important_subset_val = copy.deepcopy(data_to_add_train)[val_index]\n",
    "            test_data_to_add = copy.deepcopy(data_to_add_test)\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(important_subset_tr)\n",
    "            important_subset_tr = scaler.transform(important_subset_tr).astype(np.float32)\n",
    "            important_subset_val = scaler.transform(important_subset_val).astype(np.float32)\n",
    "            test_data_to_add = scaler.transform(test_data_to_add).astype(np.float32)\n",
    "\n",
    "            tr_x = np.hstack((tr_x, important_subset_tr))\n",
    "            val_x = np.hstack((val_x, important_subset_val))\n",
    "            te_x = np.hstack((te_x, test_data_to_add))\n",
    "            \n",
    "        train_dataloader, val_dataloader = pytorch_dataset_and_dataloader(tr_x, tr_y, val_x, val_y, batch_size, \"train\")\n",
    "        \n",
    "        # instantiate a newly initialized model and a new optimize (adam aggregates gradients so it needs to be reset)\n",
    "        model = NeuralNetwork(n_shared_hidden_layers, shared_hidden_size_list, n_non_shared_hidden_layers, \n",
    "                              non_shared_hidden_size_list, drop, n_components_to_keep, indices_to_split, \n",
    "                              output_size, n_components_to_keep, False).to(device)\n",
    "\n",
    "        if loss == \"mse\":\n",
    "            loss_fn = nn.MSELoss()\n",
    "        elif loss == \"huber\":\n",
    "            loss_fn = nn.HuberLoss(delta=0.5)\n",
    "        elif loss == \"cosine\":\n",
    "            loss_fn = nn.CosineSimilarity()\n",
    "        elif loss == \"corrcoef\":\n",
    "            loss_fn = corrcoef\n",
    "        elif loss == \"torchcorrcoef\":\n",
    "            loss_fn = torch_corrcoef\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "        early_stop_counter = 0\n",
    "        best_loss = -1\n",
    "        for epoch in range(n_epoch):\n",
    "\n",
    "            # train for one full epochearly_stop_counter gather training_loss\n",
    "            loss_train, corr_train = train(train_dataloader, model, loss_fn, loss, optimizer, device)\n",
    "            # compute the validation loss after the epoch\n",
    "            loss_val, corr_val, pred_val_list = val(val_dataloader, model, loss_fn, loss, device)\n",
    "\n",
    "            # early stopping stuff\n",
    "            early_stop_counter += 1\n",
    "            if corr_val > best_loss:\n",
    "                best_loss = corr_val\n",
    "                early_stop_counter = 0\n",
    "                swa_model = AveragedModel(model)\n",
    "\n",
    "            if early_stop_counter == early_stopping_epochs:\n",
    "                break\n",
    "            \n",
    "            if early_stop_counter > 1:\n",
    "                swa_model.update_parameters(model)\n",
    "\n",
    "            print(f\"OUTER LOOP epoch {epoch}\")\n",
    "            print(f\"training loss: {loss_train}, corr train: {corr_train}, validation_loss: {loss_val}, corr val: {corr_val}\")\n",
    "    \n",
    "        torch.optim.swa_utils.update_bn(train_dataloader, swa_model)\n",
    "        # compute the validation loss after the epoch\n",
    "        loss_val, corr_val, pred_val_list = val(val_dataloader, swa_model, loss_fn, loss, device)\n",
    "        print(f\"Computing for the SWA model. validation_loss: {loss_val}, corr val: {corr_val}\")\n",
    "\n",
    "        test_dataset = CompetitionDataset((te_x,), mode='test')\n",
    "        test_dataloader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size, drop_last=False)\n",
    "        test_predictions = test(test_dataloader, swa_model, device)\n",
    "        test_predictions = np.concatenate(test_predictions)\n",
    "        test_predictions = scale(test_predictions, axis=1)\n",
    "        if dataset == \"multiome\":\n",
    "            test_predictions = select_indices_multiome(test_predictions)\n",
    "        \n",
    "        test_predictions_dic[k].append(test_predictions)\n",
    "        # pickle.dump(test_predictions_dic, open(f\"test_predictions_dic_{dataset}_{k}.p\", \"wb\"))\n",
    "\n",
    "        fold_number += 1\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba35f16c-473d-4746-8065-5dd5bf2b0a33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80df68b-6e47-4146-ac40-2164616aef77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6f8f846d-d843-4bfc-a8f9-3065794b28c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T22:06:08.167619Z",
     "iopub.status.busy": "2022-11-08T22:06:08.167346Z",
     "iopub.status.idle": "2022-11-08T22:06:08.186679Z",
     "shell.execute_reply": "2022-11-08T22:06:08.186238Z",
     "shell.execute_reply.started": "2022-11-08T22:06:08.167596Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d34dd8-42e7-4999-81cd-14a3a9187430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068ce3f8-d3ae-405e-a553-d7ac655d0d7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "e3e1e39c-89cc-49bf-9201-f1c6ff165b1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T00:23:14.991369Z",
     "iopub.status.busy": "2022-11-09T00:23:14.991070Z",
     "iopub.status.idle": "2022-11-09T00:23:14.994766Z",
     "shell.execute_reply": "2022-11-09T00:23:14.994189Z",
     "shell.execute_reply.started": "2022-11-09T00:23:14.991346Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def modify_predictions(std_preds):\n",
    "\n",
    "    cutoff_one = np.quantile(std_preds, 0.8)\n",
    "\n",
    "    std_preds[std_preds > cutoff_one] = std_preds[std_preds > cutoff_one]-0.05*std_preds[std_preds > cutoff_one]\n",
    "    \n",
    "    return std_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "97ecc4cf-1615-4f7e-99e5-9589e43dde9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T00:23:15.173213Z",
     "iopub.status.busy": "2022-11-09T00:23:15.173006Z",
     "iopub.status.idle": "2022-11-09T00:23:15.176892Z",
     "shell.execute_reply": "2022-11-09T00:23:15.176311Z",
     "shell.execute_reply.started": "2022-11-09T00:23:15.173194Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = np.concatenate(pred_val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "85edbc04-d20c-4cef-ab23-13aedcfaabfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T00:23:15.373773Z",
     "iopub.status.busy": "2022-11-09T00:23:15.373580Z",
     "iopub.status.idle": "2022-11-09T00:23:15.376873Z",
     "shell.execute_reply": "2022-11-09T00:23:15.376294Z",
     "shell.execute_reply.started": "2022-11-09T00:23:15.373756Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_preds = copy.deepcopy(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b454ef1-36af-4026-a69c-b8ea593cb235",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db70231-bf58-4a9b-a70d-5081102efa09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_preds = modify_predictions(new_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "1a9ca889-f07f-4a24-8fb8-ad70475625ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T00:23:09.318397Z",
     "iopub.status.busy": "2022-11-09T00:23:09.317983Z",
     "iopub.status.idle": "2022-11-09T00:23:09.745113Z",
     "shell.execute_reply": "2022-11-09T00:23:09.744697Z",
     "shell.execute_reply.started": "2022-11-09T00:23:09.318377Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "corr_list = []\n",
    "\n",
    "for i in range(preds.shape[0]):\n",
    "    \n",
    "    corr = pearsonr(new_preds[i], val_y[i])[0]\n",
    "    corr_list.append(corr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "8e29ddb6-c3cb-49ce-9dcb-ba31330bb2ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T00:23:09.929110Z",
     "iopub.status.busy": "2022-11-09T00:23:09.928916Z",
     "iopub.status.idle": "2022-11-09T00:23:09.932577Z",
     "shell.execute_reply": "2022-11-09T00:23:09.932114Z",
     "shell.execute_reply.started": "2022-11-09T00:23:09.929092Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9045159243193208\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(corr_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c97678-bf4c-446c-a5e8-05469578665f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc24b273-dfe7-456c-8840-f6f649f5feee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56be61fb-576e-4efb-8a81-36f155ebb41f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92006018-0cb3-43f1-ba91-ff2bbf8eb1ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T10:32:47.179476Z",
     "iopub.status.busy": "2022-09-20T10:32:47.179199Z",
     "iopub.status.idle": "2022-09-20T10:32:47.182033Z",
     "shell.execute_reply": "2022-09-20T10:32:47.181592Z",
     "shell.execute_reply.started": "2022-09-20T10:32:47.179454Z"
    }
   },
   "source": [
    "# generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7d69b4c9-7631-49b9-97f2-e2b2ed9dd4fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T09:45:25.550528Z",
     "iopub.status.busy": "2022-11-08T09:45:25.550246Z",
     "iopub.status.idle": "2022-11-08T09:45:25.553263Z",
     "shell.execute_reply": "2022-11-08T09:45:25.552837Z",
     "shell.execute_reply.started": "2022-11-08T09:45:25.550504Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds_final = test_predictions_dic[\"all_donor\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8229836f-a827-4a50-b794-e96e114d43f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T09:44:41.438406Z",
     "iopub.status.busy": "2022-11-08T09:44:41.438193Z",
     "iopub.status.idle": "2022-11-08T09:45:01.372205Z",
     "shell.execute_reply": "2022-11-08T09:45:01.371717Z",
     "shell.execute_reply.started": "2022-11-08T09:44:41.438387Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_sub = pd.read_csv(\"best_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a1d882cd-c2ab-44bb-8361-cfe29843b960",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T09:45:01.373425Z",
     "iopub.status.busy": "2022-11-08T09:45:01.373209Z",
     "iopub.status.idle": "2022-11-08T09:45:05.285981Z",
     "shell.execute_reply": "2022-11-08T09:45:05.285464Z",
     "shell.execute_reply.started": "2022-11-08T09:45:01.373405Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rows = pickle.load(open(\"multiome_files/cell_id_to_numbers.p\", \"rb\"))\n",
    "cols = pickle.load(open(\"multiome_files/gene_id_to_numbers.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "61ac337c-8bff-46c9-ad16-1d7273c39519",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T09:45:34.306530Z",
     "iopub.status.busy": "2022-11-08T09:45:34.306254Z",
     "iopub.status.idle": "2022-11-08T09:45:34.309004Z",
     "shell.execute_reply": "2022-11-08T09:45:34.308580Z",
     "shell.execute_reply.started": "2022-11-08T09:45:34.306507Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# preds_final = test_predictions[rows, cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1ea85b3b-8a5d-4a81-aa84-792e0ebb9862",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T09:45:30.748697Z",
     "iopub.status.busy": "2022-11-08T09:45:30.748424Z",
     "iopub.status.idle": "2022-11-08T09:45:31.712994Z",
     "shell.execute_reply": "2022-11-08T09:45:31.712567Z",
     "shell.execute_reply.started": "2022-11-08T09:45:30.748675Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9861383382105229, 0.0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(best_sub[\"target\"].values[-len(preds_final):], preds_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "86dd1c8d-73c0-4f6b-a1a4-b0debc820d02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T09:45:38.411797Z",
     "iopub.status.busy": "2022-11-08T09:45:38.411519Z",
     "iopub.status.idle": "2022-11-08T09:45:38.695132Z",
     "shell.execute_reply": "2022-11-08T09:45:38.694620Z",
     "shell.execute_reply.started": "2022-11-08T09:45:38.411774Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20587/977818632.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  best_sub[\"target\"][-len(preds_final):] = preds_final\n"
     ]
    }
   ],
   "source": [
    "best_sub[\"target\"][-len(preds_final):] = preds_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f29811c7-df8f-40bb-8ea5-14a006c084b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T09:45:38.768852Z",
     "iopub.status.busy": "2022-11-08T09:45:38.768610Z",
     "iopub.status.idle": "2022-11-08T09:45:39.142860Z",
     "shell.execute_reply": "2022-11-08T09:45:39.142335Z",
     "shell.execute_reply.started": "2022-11-08T09:45:38.768827Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_sub = best_sub.set_index(\"row_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c73e2150-a8a8-4a47-ba9c-7c01406501ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T09:45:40.495068Z",
     "iopub.status.busy": "2022-11-08T09:45:40.494773Z",
     "iopub.status.idle": "2022-11-08T09:45:40.508032Z",
     "shell.execute_reply": "2022-11-08T09:45:40.507628Z",
     "shell.execute_reply.started": "2022-11-08T09:45:40.495044Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.346263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.257694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.737524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.998595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.257316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65744175</th>\n",
       "      <td>4.328752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65744176</th>\n",
       "      <td>-0.571734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65744177</th>\n",
       "      <td>-0.597907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65744178</th>\n",
       "      <td>0.230664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65744179</th>\n",
       "      <td>4.089696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65744180 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            target\n",
       "row_id            \n",
       "0        -1.346263\n",
       "1        -1.257694\n",
       "2        -0.737524\n",
       "3         5.998595\n",
       "4         8.257316\n",
       "...            ...\n",
       "65744175  4.328752\n",
       "65744176 -0.571734\n",
       "65744177 -0.597907\n",
       "65744178  0.230664\n",
       "65744179  4.089696\n",
       "\n",
       "[65744180 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(best_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0ad33aaf-97d0-4458-bfb8-43da4d828526",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T09:45:42.499079Z",
     "iopub.status.busy": "2022-11-08T09:45:42.498785Z",
     "iopub.status.idle": "2022-11-08T09:47:59.097636Z",
     "shell.execute_reply": "2022-11-08T09:47:59.097132Z",
     "shell.execute_reply.started": "2022-11-08T09:45:42.499057Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_sub.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800e3169-da95-4db4-9106-b192bccb933f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1566c93c-f65f-4f62-9dcc-50381e18a4f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T17:09:31.602269Z",
     "iopub.status.busy": "2022-11-05T17:09:31.601891Z",
     "iopub.status.idle": "2022-11-05T17:09:31.605059Z",
     "shell.execute_reply": "2022-11-05T17:09:31.604512Z",
     "shell.execute_reply.started": "2022-11-05T17:09:31.602247Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f14a26-6494-42e3-8034-05dcc8621a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0007314-b238-4659-8d15-bdef23c30508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594800df-cf65-4d5f-97af-919f3885c7f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c725b1-0493-46d2-98e6-bb6ad1ab0cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "791e1c66-64bb-4d85-b06d-d01232b523b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-16T21:34:08.290391Z",
     "iopub.status.busy": "2022-10-16T21:34:08.290095Z",
     "iopub.status.idle": "2022-10-16T21:34:08.293203Z",
     "shell.execute_reply": "2022-10-16T21:34:08.292769Z",
     "shell.execute_reply.started": "2022-10-16T21:34:08.290367Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_predictions_dic = test_predictions_dic[\"all_donor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab53fbd7-aecf-4ded-a708-a9e11c89de6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-16T21:34:12.996016Z",
     "iopub.status.busy": "2022-10-16T21:34:12.995711Z",
     "iopub.status.idle": "2022-10-16T21:34:13.061205Z",
     "shell.execute_reply": "2022-10-16T21:34:13.060694Z",
     "shell.execute_reply.started": "2022-10-16T21:34:12.995992Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds_all_donor = [np.concatenate(test_predictions_dic[i]) for i in range(len(test_predictions_dic))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71e57be0-a9f1-4396-9236-ae1a71785a07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-16T21:34:20.584359Z",
     "iopub.status.busy": "2022-10-16T21:34:20.584064Z",
     "iopub.status.idle": "2022-10-16T21:34:21.947744Z",
     "shell.execute_reply": "2022-10-16T21:34:21.947231Z",
     "shell.execute_reply.started": "2022-10-16T21:34:20.584335Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = np.median(preds_all_donor, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d07d6c5f-20cd-4a43-8d66-9b04f834f9b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-16T21:34:26.000319Z",
     "iopub.status.busy": "2022-10-16T21:34:26.000032Z",
     "iopub.status.idle": "2022-10-16T21:34:26.003975Z",
     "shell.execute_reply": "2022-10-16T21:34:26.003519Z",
     "shell.execute_reply.started": "2022-10-16T21:34:26.000297Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48663, 140)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd8deadc-0043-4954-a27d-fa8d63dc47a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-16T21:34:30.543260Z",
     "iopub.status.busy": "2022-10-16T21:34:30.542966Z",
     "iopub.status.idle": "2022-10-16T21:34:30.574070Z",
     "shell.execute_reply": "2022-10-16T21:34:30.573583Z",
     "shell.execute_reply.started": "2022-10-16T21:34:30.543236Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = np.concatenate(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05ee938e-a476-4e9a-9f39-58c46cd35600",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-16T21:34:30.700169Z",
     "iopub.status.busy": "2022-10-16T21:34:30.699922Z",
     "iopub.status.idle": "2022-10-16T21:34:46.351434Z",
     "shell.execute_reply": "2022-10-16T21:34:46.350892Z",
     "shell.execute_reply.started": "2022-10-16T21:34:30.700149Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv(\"best_submission.csv\")\n",
    "submission_df = submission_df.set_index(\"row_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a52250-0ee1-4705-bd07-366975b5998a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9a0d87-72ae-4e8f-808e-3028390e3b07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "97e4e5ae-dff4-4d24-8542-a90e88e2972e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-16T21:37:45.813726Z",
     "iopub.status.busy": "2022-10-16T21:37:45.813370Z",
     "iopub.status.idle": "2022-10-16T21:37:45.823683Z",
     "shell.execute_reply": "2022-10-16T21:37:45.823270Z",
     "shell.execute_reply.started": "2022-10-16T21:37:45.813707Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_df[\"target\"][:test_x.shape[0]*140] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "08fe4a71-5c46-4ea9-9e44-f0dfbe0b3ecb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-16T21:37:45.824920Z",
     "iopub.status.busy": "2022-10-16T21:37:45.824572Z",
     "iopub.status.idle": "2022-10-16T21:37:45.832551Z",
     "shell.execute_reply": "2022-10-16T21:37:45.832153Z",
     "shell.execute_reply.started": "2022-10-16T21:37:45.824902Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.950046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.661454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.602814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.410881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.907983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65744175</th>\n",
       "      <td>6.206671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65744176</th>\n",
       "      <td>0.045758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65744177</th>\n",
       "      <td>0.032102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65744178</th>\n",
       "      <td>1.350810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65744179</th>\n",
       "      <td>5.112195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65744180 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             target\n",
       "row_id             \n",
       "0         -2.950046\n",
       "1         -2.661454\n",
       "2         -1.602814\n",
       "3          9.410881\n",
       "4         12.907983\n",
       "...             ...\n",
       "65744175   6.206671\n",
       "65744176   0.045758\n",
       "65744177   0.032102\n",
       "65744178   1.350810\n",
       "65744179   5.112195\n",
       "\n",
       "[65744180 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(submission_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0d16780f-f084-43ca-8a34-38899d99a1bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-16T21:37:45.833335Z",
     "iopub.status.busy": "2022-10-16T21:37:45.833162Z",
     "iopub.status.idle": "2022-10-16T21:39:37.791925Z",
     "shell.execute_reply": "2022-10-16T21:39:37.791398Z",
     "shell.execute_reply.started": "2022-10-16T21:37:45.833318Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393f12a6-24a1-4298-b036-e0097ad79b80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db18e52f-4bfb-48a8-ae54-5d7313251473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d9a2db-f890-4382-aff7-01188c87a190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4838a82-d5c6-47b2-aaa1-fd2afebd7829",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569408a7-5d00-45cf-a8d2-193abcdbf06c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52519f5a-a6d9-4c21-a0df-51cf4e52b52e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd4b61f-3e6e-4427-932a-634a45c8bd7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606dbf01-635b-4310-bd7e-80269c972b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bb19bc-3ae1-4bc5-b048-a7b93ce111d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf63b82-5218-458a-a7f9-5396b70a2bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
