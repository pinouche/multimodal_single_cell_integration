{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a189685c-3d19-4ad5-8a2f-17af4742e642",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T10:49:24.186752Z",
     "iopub.status.busy": "2022-09-06T10:49:24.186411Z",
     "iopub.status.idle": "2022-09-06T10:49:25.067914Z",
     "shell.execute_reply": "2022-09-06T10:49:25.067418Z",
     "shell.execute_reply.started": "2022-09-06T10:49:24.186673Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import LongformerModel, LongformerConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92de856c-e184-4e9b-b901-a1f6fd1a1235",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T10:49:25.069339Z",
     "iopub.status.busy": "2022-09-06T10:49:25.068991Z",
     "iopub.status.idle": "2022-09-06T10:49:25.762956Z",
     "shell.execute_reply": "2022-09-06T10:49:25.762448Z",
     "shell.execute_reply.started": "2022-09-06T10:49:25.069313Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tables\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import pearsonr\n",
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dff4f77e-d1f2-45e7-b96c-88e35a71d8a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T10:49:25.763948Z",
     "iopub.status.busy": "2022-09-06T10:49:25.763736Z",
     "iopub.status.idle": "2022-09-06T10:49:25.844402Z",
     "shell.execute_reply": "2022-09-06T10:49:25.843939Z",
     "shell.execute_reply.started": "2022-09-06T10:49:25.763929Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "537dec44-7121-48aa-bcb9-9d82aed8765b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T10:49:25.845624Z",
     "iopub.status.busy": "2022-09-06T10:49:25.845437Z",
     "iopub.status.idle": "2022-09-06T10:49:25.848508Z",
     "shell.execute_reply": "2022-09-06T10:49:25.848080Z",
     "shell.execute_reply.started": "2022-09-06T10:49:25.845605Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "use_amp = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88d8b08d-7f67-4e6c-8ec5-bc0ef67fa1ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T10:49:29.334997Z",
     "iopub.status.busy": "2022-09-06T10:49:29.334689Z",
     "iopub.status.idle": "2022-09-06T10:49:29.337636Z",
     "shell.execute_reply": "2022-09-06T10:49:29.337172Z",
     "shell.execute_reply.started": "2022-09-06T10:49:29.334974Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67acdef5-b1d6-4454-b75f-895786940ca3",
   "metadata": {},
   "source": [
    "# load the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71b9fa58-233a-4ac0-a822-fc2588b1d4d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T10:49:36.390969Z",
     "iopub.status.busy": "2022-09-06T10:49:36.390663Z",
     "iopub.status.idle": "2022-09-06T10:49:36.394617Z",
     "shell.execute_reply": "2022-09-06T10:49:36.394175Z",
     "shell.execute_reply.started": "2022-09-06T10:49:36.390946Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def identify_constant_columns(data):\n",
    "\n",
    "    constant_cols_list = []\n",
    "\n",
    "    for index in range(data.shape[1]):\n",
    "\n",
    "        col = data[:, index]\n",
    "        is_unique = len(np.unique(col)) == 1\n",
    "\n",
    "        if is_unique:\n",
    "            constant_cols_list.append(index)\n",
    "            \n",
    "    return constant_cols_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e187403-c288-46d7-8fef-6127e70ba28a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T10:49:36.541492Z",
     "iopub.status.busy": "2022-09-06T10:49:36.541272Z",
     "iopub.status.idle": "2022-09-06T10:49:36.547132Z",
     "shell.execute_reply": "2022-09-06T10:49:36.546664Z",
     "shell.execute_reply.started": "2022-09-06T10:49:36.541472Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the paths to load the data\n",
    "\n",
    "def load_dataset(data_name):\n",
    "\n",
    "    dir_path = \"/kaggle/input/open-problems-multimodal/\"\n",
    "\n",
    "    if data_name == \"citeseq\":\n",
    "        train_x_path = os.path.join(dir_path,\"train_cite_inputs.h5\")\n",
    "        train_y_path = os.path.join(dir_path,\"train_cite_targets.h5\")\n",
    "        test_x_path = os.path.join(dir_path,\"test_cite_inputs.h5\")\n",
    "\n",
    "    elif data_name == \"multiome\":\n",
    "        train_x_path = os.path.join(dir_path,\"train_multi_inputs.h5\")\n",
    "        train_y_path = os.path.join(dir_path,\"train_multi_targets.h5\")\n",
    "        test_x_path = os.path.join(dir_path,\"test_multi_inputs.h5\")\n",
    "\n",
    "    else:\n",
    "        raise NameError(f\"{data_name} is not a valid name: choose between 'siteseq' and 'multiome'\")\n",
    "        \n",
    "    train_x = pd.read_hdf(train_x_path).to_numpy()\n",
    "    train_y = pd.read_hdf(train_y_path).to_numpy()\n",
    "    \n",
    "    test_x = pd.read_hdf(test_x_path).to_numpy()\n",
    "    \n",
    "    # some columns in the training sets are constant (zeros), remove them\n",
    "    constant_columns_train = identify_constant_columns(train_x)\n",
    "    train_x = train_x[:, [i for i in range(train_x.shape[1]) if i not in constant_columns_train]]\n",
    "    test_x = test_x[:, [i for i in range(test_x.shape[1]) if i not in constant_columns_train]]\n",
    "    \n",
    "    return train_x, train_y, test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "956ff734-5eb7-4eef-9410-119da9f3f7f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T10:49:36.746428Z",
     "iopub.status.busy": "2022-09-06T10:49:36.746183Z",
     "iopub.status.idle": "2022-09-06T10:49:36.748796Z",
     "shell.execute_reply": "2022-09-06T10:49:36.748341Z",
     "shell.execute_reply.started": "2022-09-06T10:49:36.746406Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# submission_path = os.path.join(dir_path,\"sample_submission.csv\")\n",
    "# evaluation_ids_path = os.path.join(dir_path,\"evaluation_ids.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f22ceb4-ff67-4780-a253-9535b5cd4ea8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa119d3a-3012-479e-90bb-c1f195353f66",
   "metadata": {},
   "source": [
    "# Pytorch util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4d6902-a9ec-41c3-ba0a-206e645af71b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6221cfe-c15c-4634-8fbf-dca6938cc513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b773091-ab25-4d65-9168-cb7c5305daa6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T10:49:39.613015Z",
     "iopub.status.busy": "2022-09-06T10:49:39.612744Z",
     "iopub.status.idle": "2022-09-06T10:49:39.622617Z",
     "shell.execute_reply": "2022-09-06T10:49:39.622156Z",
     "shell.execute_reply.started": "2022-09-06T10:49:39.612992Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training loop for each epoch\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer, device, use_amp=use_amp):\n",
    "    \n",
    "    num_batches = len(dataloader)\n",
    "    model.train()\n",
    "    loss = 0\n",
    "    corr = 0\n",
    "    \n",
    "    for data_dic in dataloader:\n",
    "        X, y = data_dic['x'].to(device), data_dic['y'].to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        with torch.autocast(device_type=device, dtype=torch.float16, enabled=use_amp):\n",
    "            pred = model(X)\n",
    "            train_loss = loss_fn(pred, y)\n",
    "            \n",
    "        loss += train_loss.item()\n",
    "        corr += np.mean([pearsonr(pred[i].cpu().detach().numpy(), y[i].cpu().detach().numpy())[0] for i in range(pred.shape[0])])\n",
    "        \n",
    "        # Backpropagation\n",
    "        opt.zero_grad()\n",
    "        scaler.scale(train_loss).backward()\n",
    "        scaler.step(opt)\n",
    "        scaler.update()\n",
    "        \n",
    "        # these 3 lines are to use without the torch.amp mixed precision\n",
    "        # optimizer.zero_grad()\n",
    "        # train_loss.backward()\n",
    "        # optimizer.step()\n",
    "    \n",
    "    loss /= num_batches\n",
    "    corr /= num_batches\n",
    "    \n",
    "    return loss, corr\n",
    "\n",
    "\n",
    "# validation loop for each epoch\n",
    "def val(dataloader, model, loss_fn, device, use_amp=use_amp):\n",
    "    \n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    corr = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data_dic in dataloader:\n",
    "            X, y = data_dic['x'].to(device), data_dic['y'].to(device)\n",
    "            \n",
    "            with torch.autocast(device_type=device, dtype=torch.float16, enabled=use_amp):\n",
    "                pred = model(X)\n",
    "                val_loss = loss_fn(pred, y)\n",
    "                \n",
    "            loss += val_loss.item()    \n",
    "            corr += np.mean([pearsonr(pred[i].cpu().detach().numpy(), y[i].cpu().detach().numpy())[0] for i in range(pred.shape[0])])\n",
    "            \n",
    "    loss /= num_batches\n",
    "    corr /= num_batches\n",
    "    \n",
    "    return loss, corr\n",
    "\n",
    "# make predictions on the test set (dataloader is only made of x)\n",
    "\n",
    "def test(dataloader, model, loss_fn, device):\n",
    "    \n",
    "    pred_list = []\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data_dic in dataloader:\n",
    "            \n",
    "            X = data_dic['x'].to(device)\n",
    "            pred = model(X)\n",
    "            pred_list.append(pred)\n",
    "    \n",
    "    return pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b13a17ce-db91-400c-9c43-2675a188cf85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T10:49:40.137884Z",
     "iopub.status.busy": "2022-09-06T10:49:40.137605Z",
     "iopub.status.idle": "2022-09-06T10:49:40.143451Z",
     "shell.execute_reply": "2022-09-06T10:49:40.142969Z",
     "shell.execute_reply.started": "2022-09-06T10:49:40.137861Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataset class that loads the data and prepare it for the pytorch dataloader\n",
    "\n",
    "class CompetitionDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_tuple, mode='train'):\n",
    "        self.mode = mode\n",
    "        \n",
    "        if self.mode == \"train\":\n",
    "            assert len(data_tuple) == 2, \"`data_tuple` should have lenght 2\"\n",
    "            data_x, data_y = data_tuple\n",
    "        elif self.mode == \"test\":\n",
    "            assert len(data_tuple) == 1, \"`data_tuple` should have length 1\"\n",
    "            data_x = data_tuple[0]\n",
    "        else:\n",
    "            raise NameError(f\"{self.mode} is not a valid mode: choose between 'train' and 'test'\")\n",
    "\n",
    "        self.filenames = dict()\n",
    "        self.filenames['x'] = data_x\n",
    "        \n",
    "        if self.mode == \"train\":\n",
    "            self.filenames['y'] = data_y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch = dict()\n",
    "        \n",
    "        batch['x'] = torch.from_numpy(self.filenames['x'][index])\n",
    "        \n",
    "        if self.mode == \"train\":\n",
    "            batch['y'] = torch.from_numpy(self.filenames['y'][index])\n",
    "        \n",
    "        return batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b84dc126-3ce0-431e-b188-a4f607ad555e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T10:49:41.040752Z",
     "iopub.status.busy": "2022-09-06T10:49:41.040470Z",
     "iopub.status.idle": "2022-09-06T10:49:41.045012Z",
     "shell.execute_reply": "2022-09-06T10:49:41.044539Z",
     "shell.execute_reply.started": "2022-09-06T10:49:41.040730Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pytorch_dataset_and_dataloader(train_x, train_y, train_index, val_index, batch_size = 256, mode = \"train\"):\n",
    "    \n",
    "    tr_x, tr_y = train_x[train_index], train_y[train_index]\n",
    "    val_x, val_y = train_x[val_index], train_y[val_index]\n",
    "\n",
    "    train_dataset = CompetitionDataset((tr_x, tr_y), mode)\n",
    "    val_dataset = CompetitionDataset((val_x, val_y), mode) # here \"train\" is also used for validation\n",
    "    \n",
    "    train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size, drop_last=False)\n",
    "    val_dataloader = DataLoader(val_dataset, shuffle=True, batch_size=batch_size, drop_last=False)\n",
    "    \n",
    "    return train_dataloader, val_dataloader, val_x, val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d4462e-a9d3-4830-b76f-f492f79c7e2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6daa5e-0796-459f-a4d0-8159efa89f0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "247a9c0d-8be7-4f68-88b8-b9e3ddfc8926",
   "metadata": {},
   "source": [
    "# Pytorch longformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40e21f66-d619-4d83-9f6c-1fceb4c3b72a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T18:03:54.994832Z",
     "iopub.status.busy": "2022-09-03T18:03:54.994565Z",
     "iopub.status.idle": "2022-09-03T18:03:54.999493Z",
     "shell.execute_reply": "2022-09-03T18:03:54.999035Z",
     "shell.execute_reply.started": "2022-09-03T18:03:54.994809Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModifiedLongformer(nn.Module):\n",
    "    def __init__(self, num_hidden_layers, model, output_size):\n",
    "        super(ModifiedLongformer, self).__init__()\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        \n",
    "        self.model = model\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "        self.lazy_linear = nn.LazyLinear(output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.model[0](x)\n",
    "        \n",
    "        if self.num_hidden_layers > 1:\n",
    "            for n_layer in range(1, self.num_hidden_layers):\n",
    "                x = self.model[n_layer](x[0])\n",
    "        \n",
    "        x = self.flatten(x[0]) # x is a tuple here, so we take x[0]\n",
    "        x = self.lazy_linear(x)\n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f938d88-50be-41c6-baa2-82b536dd6be6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T18:03:57.991866Z",
     "iopub.status.busy": "2022-09-03T18:03:57.991577Z",
     "iopub.status.idle": "2022-09-03T18:05:35.699182Z",
     "shell.execute_reply": "2022-09-03T18:05:35.698621Z",
     "shell.execute_reply.started": "2022-09-03T18:03:57.991842Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_x, train_y, test_x = load_dataset(data_name=\"citeseq\")\n",
    "\n",
    "#train_x = np.hstack((train_x, np.zeros((train_x.shape[0], 3))))\n",
    "train_x = np.expand_dims(train_x, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d75cb03-06d1-4ecf-be0b-ee07fa82c2b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T18:05:35.700474Z",
     "iopub.status.busy": "2022-09-03T18:05:35.700257Z",
     "iopub.status.idle": "2022-09-03T18:05:35.703201Z",
     "shell.execute_reply": "2022-09-03T18:05:35.702769Z",
     "shell.execute_reply.started": "2022-09-03T18:05:35.700454Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_x = train_x[:, :-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93776c1b-39c4-4549-abd3-6f3581c78707",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T18:05:35.704131Z",
     "iopub.status.busy": "2022-09-03T18:05:35.703824Z",
     "iopub.status.idle": "2022-09-03T18:05:35.707107Z",
     "shell.execute_reply": "2022-09-03T18:05:35.706684Z",
     "shell.execute_reply.started": "2022-09-03T18:05:35.704112Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hyperparams\n",
    "\n",
    "# for the longformer\n",
    "\n",
    "num_hidden_layers = 1\n",
    "hidden_size = 10 # hidden size must be a multiple of number of heads, as the dim of each heads will then be hidden_size/num_attention_heads\n",
    "num_attention_heads = 5\n",
    "attention_window = 216\n",
    "\n",
    "# for the output layer\n",
    "output_size = train_y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a00ead3a-a38e-48ba-bd60-9783f4849daf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T18:05:35.708312Z",
     "iopub.status.busy": "2022-09-03T18:05:35.707990Z",
     "iopub.status.idle": "2022-09-03T18:05:35.710632Z",
     "shell.execute_reply": "2022-09-03T18:05:35.710220Z",
     "shell.execute_reply.started": "2022-09-03T18:05:35.708293Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "687b70f8-fdff-4a5a-8a85-fe0576ca5d46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T18:05:35.711404Z",
     "iopub.status.busy": "2022-09-03T18:05:35.711219Z",
     "iopub.status.idle": "2022-09-03T18:05:35.714300Z",
     "shell.execute_reply": "2022-09-03T18:05:35.713891Z",
     "shell.execute_reply.started": "2022-09-03T18:05:35.711386Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_cv_fold = 5\n",
    "n_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a02a42-dd36-4bb4-9f79-f5f8032132b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T18:05:55.950962Z",
     "iopub.status.busy": "2022-09-03T18:05:55.950669Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing for fold number 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/saturn/lib/python3.9/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTER LOOP epoch 0\n",
      "training loss: 5.686488068259959, corr train: 0.766577659080332, validation_loss: (4.280856034990768, 0.834438721262542)\n",
      "OUTER LOOP epoch 1\n",
      "training loss: 4.208691983042275, corr train: 0.8259350987057289, validation_loss: (3.2409450081032767, 0.8635845790247748)\n",
      "OUTER LOOP epoch 2\n",
      "training loss: 3.0387585826920263, corr train: 0.872311985638506, validation_loss: (2.991883960038843, 0.8828303415887628)\n"
     ]
    }
   ],
   "source": [
    "fold_number = 0\n",
    "\n",
    "for train_index_outer, val_index_outer in KFold(n_cv_fold, shuffle=True, random_state=0).split(train_x):\n",
    "    print(f\"computing for fold number {fold_number+1}\")\n",
    "    \n",
    "    train_dataloader, val_dataloader, val_x, val_y = pytorch_dataset_and_dataloader(train_x, train_y, train_index_outer, val_index_outer, batch_size, \"train\")\n",
    "    \n",
    "    # instantiate a newly initialized model and a new optimize (adam aggregates gradients so it needs to be reset)\n",
    "    config = LongformerConfig(num_hidden_layers = num_hidden_layers, \n",
    "                              hidden_size = hidden_size, \n",
    "                              num_attention_heads = num_attention_heads,\n",
    "                              attention_window = attention_window,\n",
    "                              max_position_embeddings = 512,\n",
    "                              vocab_size = 512,\n",
    "                              use_cache = False)\n",
    "    \n",
    "    model = LongformerModel(config).encoder.layer\n",
    "    model = ModifiedLongformer(num_hidden_layers, model, output_size).to(device)\n",
    "    \n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        \n",
    "        # train for one full epoch and gather training_loss\n",
    "        loss_train, corr_train = train(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        # compute the validation loss after the epoch\n",
    "        loss_val = val(val_dataloader, model, loss_fn, device)\n",
    "        \n",
    "        print(f\"OUTER LOOP epoch {epoch}\")\n",
    "        print(f\"training loss: {loss_train}, corr train: {corr_train}, validation_loss: {loss_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcc299a-b08f-44ad-b9c4-569ad0890e4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c6c618-66ab-4569-847e-fd7de5a594e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798d06e0-1d2f-4059-8e38-5b4d95985782",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79e55968-af24-4e7e-a757-9511d5836070",
   "metadata": {},
   "source": [
    "# Pytorch Simple MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45006b2e-fb01-4dca-97e0-98207daf3123",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T10:49:49.202847Z",
     "iopub.status.busy": "2022-09-06T10:49:49.202544Z",
     "iopub.status.idle": "2022-09-06T10:49:49.209798Z",
     "shell.execute_reply": "2022-09-06T10:49:49.209308Z",
     "shell.execute_reply.started": "2022-09-06T10:49:49.202824Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, n_hidden_layers, hidden_size_list, dropout_list, output_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        \n",
    "        assert len(hidden_size_list) == n_hidden_layers, f\"`hidden_size_list` should have length {n_hidden_layers}\"\n",
    "        assert len(dropout_list) == n_hidden_layers, f\"`dropout_list` should have length {n_hidden_layers}\"\n",
    "        \n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "        self.hidden_size_list = hidden_size_list\n",
    "        self.dropout_list = dropout_list\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # first layer\n",
    "        self.first_layer = nn.Sequential(\n",
    "            nn.LazyLinear(self.hidden_size_list[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.dropout_list[0]),\n",
    "            nn.BatchNorm1d(self.hidden_size_list[0]))\n",
    "        \n",
    "        # hidden layers\n",
    "        self.hidden_layers_list = nn.ModuleList()\n",
    "        for l in range(1, self.n_hidden_layers):\n",
    "            self.hidden_layers_list.append(nn.Linear(self.hidden_size_list[l-1], self.hidden_size_list[l]))\n",
    "            self.hidden_layers_list.append(nn.ReLU())\n",
    "            self.hidden_layers_list.append(nn.Dropout(self.dropout_list[l]))\n",
    "            self.hidden_layers_list.append(nn.BatchNorm1d(self.hidden_size_list[l]))\n",
    "        \n",
    "        self.output_layer = nn.Linear(self.hidden_size_list[-1], output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.first_layer(x)\n",
    "        \n",
    "        if self.n_hidden_layers > 1:\n",
    "            for l in range(1, self.n_hidden_layers):\n",
    "                x = self.hidden_layers_list[l](x)\n",
    "        \n",
    "        x = self.output_layer(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68bebd0-625a-4b23-bfc0-e331b149b238",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T10:49:51.424426Z",
     "iopub.status.busy": "2022-09-06T10:49:51.424142Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_x, train_y, test_x = load_dataset(data_name=\"citeseq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "10fee1fa-72ba-4a16-ad4c-d49b55365e00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T10:36:54.695016Z",
     "iopub.status.busy": "2022-09-03T10:36:54.694724Z",
     "iopub.status.idle": "2022-09-03T10:36:54.698279Z",
     "shell.execute_reply": "2022-09-03T10:36:54.697824Z",
     "shell.execute_reply.started": "2022-09-03T10:36:54.694993Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# network parameters\n",
    "\n",
    "n_hidden_layers = 2\n",
    "drop_out = 0.25\n",
    "\n",
    "hidden_size_list = [2056] * (n_hidden_layers-1)\n",
    "dropout_list = [drop_out] * (n_hidden_layers-1)\n",
    "\n",
    "output_size = train_y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "da5c2e86-5654-4da8-8e47-a3d17f6ad1df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T10:16:09.804538Z",
     "iopub.status.busy": "2022-09-03T10:16:09.804224Z",
     "iopub.status.idle": "2022-09-03T10:16:09.807231Z",
     "shell.execute_reply": "2022-09-03T10:16:09.806796Z",
     "shell.execute_reply.started": "2022-09-03T10:16:09.804515Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2730e2f7-885d-4cd9-82c9-55b4012191c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T10:16:10.334817Z",
     "iopub.status.busy": "2022-09-03T10:16:10.334544Z",
     "iopub.status.idle": "2022-09-03T10:16:10.337433Z",
     "shell.execute_reply": "2022-09-03T10:16:10.336983Z",
     "shell.execute_reply.started": "2022-09-03T10:16:10.334793Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_cv_fold = 5\n",
    "n_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cd31e7-a174-4168-a9a5-9f6e8980f02e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cf13e206-9da0-4af1-8126-962a60f760d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T10:45:00.412439Z",
     "iopub.status.busy": "2022-09-03T10:45:00.411935Z",
     "iopub.status.idle": "2022-09-03T10:45:00.415867Z",
     "shell.execute_reply": "2022-09-03T10:45:00.415426Z",
     "shell.execute_reply.started": "2022-09-03T10:45:00.412415Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cross validation\n",
    "\n",
    "fold_number = 0\n",
    "\n",
    "for train_index_outer, val_index_outer in KFold(n_cv_fold, shuffle=True, random_state=0).split(train_x):\n",
    "    print(f\"computing for fold number {fold_number+1}\")\n",
    "    \n",
    "    train_dataloader, val_dataloader, val_x, val_y = pytorch_dataset_and_dataloader(train_x, train_y, train_index_outer, val_index_outer, batch_size, \"train\")\n",
    "    \n",
    "    # instantiate a newly initialized model and a new optimize (adam aggregates gradients so it needs to be reset)\n",
    "    model = NeuralNetwork(n_hidden_layers-1, hidden_size_list, dropout_list, output_size).to(device)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        \n",
    "        # train for one full epoch and gather training_loss\n",
    "        loss_train, corr_train = train(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        # compute the validation loss after the epoch\n",
    "        loss_val = val(val_dataloader, model, loss_fn, device)\n",
    "        \n",
    "        print(f\"OUTER LOOP epoch {epoch}\")\n",
    "        print(f\"training loss: {loss_train}, corr train: {corr_train}, validation_loss: {loss_val}\")\n",
    "    \n",
    "    pred_train = model(torch.from_numpy(val_x).to(device))\n",
    "    pred_train = pred_train.cpu().detach().numpy()\n",
    "        \n",
    "    for train_index_inner, val_index_inner in KFold(10, shuffle=True, random_state=0).split(pred_train):\n",
    "        \n",
    "        train_dataloader, val_dataloader, _, _ = pytorch_dataset_and_dataloader(pred_train, val_y, train_index_inner, val_index_inner, batch_size, \"train\")\n",
    "        \n",
    "        # instantiate a newly initialized model and a new optimize (adam aggregates gradients so it needs to be reset)\n",
    "        model = NeuralNetwork(n_hidden_layers-1, [1024], dropout_list, output_size).to(device)\n",
    "        loss_fn = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        \n",
    "        for epoch in range(50):\n",
    "        \n",
    "            # train for one full epoch and gather training_loss\n",
    "            loss_train, corr_train = train(train_dataloader, model, loss_fn, optimizer, device)\n",
    "            # compute the validation loss after the epoch\n",
    "            loss_val = val(val_dataloader, model, loss_fn, device)\n",
    "            \n",
    "            print(f\"INNER LOOP epoch {epoch}\")\n",
    "            print(f\"training loss: {loss_train}, corr train: {corr_train}, validation_loss: {loss_val}\")\n",
    "\n",
    "    fold_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbda3d6e-919a-4732-a6b3-8d6ba64de128",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54c29de-0505-4987-9906-82d64496b618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a763bafd-ca0c-4cf5-b81f-f5476dc59740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ef65570-f9f1-4c02-b081-41a70d29cd53",
   "metadata": {},
   "source": [
    "# predictions from the model and computing metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "74e7fe20-4e00-48d2-86fb-0b27797235bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-30T15:40:02.233994Z",
     "iopub.status.busy": "2022-08-30T15:40:02.233689Z",
     "iopub.status.idle": "2022-08-30T15:40:02.427924Z",
     "shell.execute_reply": "2022-08-30T15:40:02.427443Z",
     "shell.execute_reply.started": "2022-08-30T15:40:02.233971Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "360037eb-3fa9-463f-af51-a1b2d729ac99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-30T15:44:04.499224Z",
     "iopub.status.busy": "2022-08-30T15:44:04.498930Z",
     "iopub.status.idle": "2022-08-30T15:44:04.853330Z",
     "shell.execute_reply": "2022-08-30T15:44:04.852837Z",
     "shell.execute_reply.started": "2022-08-30T15:44:04.499201Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_pearson(preds, truth):\n",
    "\n",
    "    output = model(data_x).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "79973caa-9545-4a47-86af-302b57d293d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-02T14:10:25.923032Z",
     "iopub.status.busy": "2022-09-02T14:10:25.922817Z",
     "iopub.status.idle": "2022-09-02T14:10:27.560010Z",
     "shell.execute_reply": "2022-09-02T14:10:27.559336Z",
     "shell.execute_reply.started": "2022-09-02T14:10:25.923012Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "corr_list = []\n",
    "\n",
    "for index in range(pred.shape[0]):\n",
    "    \n",
    "    if index % 5000 == 0:\n",
    "        print(index)\n",
    "    \n",
    "    corr = pearsonr(pred[index].cpu().detach().numpy(), val_y[index])[0]\n",
    "    corr_list.append(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3729abd2-03f0-47b1-8595-d2f06afe35fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-02T14:10:31.721550Z",
     "iopub.status.busy": "2022-09-02T14:10:31.721268Z",
     "iopub.status.idle": "2022-09-02T14:10:31.726094Z",
     "shell.execute_reply": "2022-09-02T14:10:31.725661Z",
     "shell.execute_reply.started": "2022-09-02T14:10:31.721527Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8875630494726452"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(corr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd69614-031e-4f62-8f0b-aa083ce2ea3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6347aac8-5fa0-492c-8503-973109a28e5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094ebc4f-d3bf-4dc1-b97e-4e34bfe8593b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
